{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Langchain\n",
    "\n",
    "notebook contains all examples in the ```Introduction to LangChain``` section of the linked course. \n",
    "\n",
    "**Note**: I am using Azure Open AI here with local authentication to eliminate the need for specifying a key. \n",
    "For more on local authentication with Azure Open AI , refer to my gist here: https://gist.github.com/vishnu1729/77ae8645974a9a310864d727d1086eec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (1.53.1)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (0.2.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-openai) (0.3.15)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (0.1.139)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-openai) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vishnumu\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising the LLM\n",
    "\n",
    "this lesson covers:\n",
    "* installing the langchain python package\n",
    "* initialize an LLM\n",
    "* get a response from the LLM using a Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Langchain Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = token_provider = get_bearer_token_provider(DefaultAzureCredential(exclude_interactive_browser_credential=False), \"https://cognitiveservices.azure.com/.default\")\n",
    " \n",
    "# https://python.langchain.com/docs/integrations/chat/azure_chat_openai/\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/switching-endpoints\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version='2024-08-01-preview',# make sure this api_version matches what is the endpoint url below\n",
    "    azure_endpoint=\"https://intel-graph-openai.openai.azure.com/openai/deployments/igrt-gpt-4o-2024-10-22/chat/completions?api-version=2024-08-01-preview\",\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Neo4j is a highly popular graph database management system designed to store, manage, and query data in the form of graphs. Unlike traditional relational databases that use tables and rows to represent data, Neo4j uses nodes, relationships, and properties to represent and store data. This structure is particularly effective for representing complex and interconnected data, such as social networks, recommendation engines, fraud detection systems, and network management.\\n\\nKey features of Neo4j include:\\n\\n1. **Graph Model**: Neo4j uses a property graph model where data is stored as nodes (entities), relationships (connections between entities), and properties (attributes of nodes and relationships).\\n\\n2. **Cypher Query Language**: Neo4j employs Cypher, a powerful and expressive query language specifically designed for working with graph data. Cypher allows users to efficiently query and manipulate the graph structure.\\n\\n3. **High Performance**: Neo4j is optimized for high performance in querying and traversing graphs, making it suitable for large-scale graph analytics and real-time data processing.\\n\\n4. **ACID Compliance**: Neo4j ensures data integrity and reliability by providing full ACID (Atomicity, Consistency, Isolation, Durability) transaction support.\\n\\n5. **Scalability**: Neo4j can scale both vertically and horizontally, enabling it to handle large datasets and distributed environments.\\n\\n6. **Rich Ecosystem**: Neo4j has a vibrant ecosystem with a variety of tools, extensions, and integrations, including support for various programming languages, drivers, and frameworks.\\n\\n7. **Community and Enterprise Editions**: Neo4j offers both a free community edition and a commercial enterprise edition with additional features and support for enterprise-level applications.\\n\\nNeo4j is widely used in various industries, including finance, telecommunications, healthcare, and logistics, for applications that benefit from leveraging the power of graph data structures.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 377, 'prompt_tokens': 13, 'total_tokens': 390, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_67802d9a6d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-da1ce4fb-e1f0-470d-b6df-da2a41ebf965-0' usage_metadata={'input_tokens': 13, 'output_tokens': 377, 'total_tokens': 390, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"What is Neo4j?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "\n",
    "As instructed in the course, we will try modify the prompt. Prompt template are resubale instructions that specifically tell the LLM what needs to be accomplished for the user's inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "template = PromptTemplate(template=\n",
    "    \"\"\"\n",
    "    You are a pirate who is hunting for treasure. Your role is to assist the customer with their navigation needs in locating the treasure.\n",
    "    Respond like a pirate. \n",
    "    Where is {island} island?\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Ahoy, matey! Ye be seekin' the Lost and Found Island, eh? Well, ye best be ready for a journey fraught with peril and adventure! That mystical isle be hidden beyond the treacherous reefs of the Seven Seas. \\n\\nStart ye voyage from the Port of No Return, head due east till ye spot the Skull Rock. From there, ye'll need to navigate through the Siren's Lagoonâ€”beware their enchanting songs, they'll lead ye astray! Keep a sharp eye on yer compass and sail towards the Blood Moon. When the night sky be red as a pirate's bandana, ye'll find the secret cove.\\n\\nThere, amidst the swirling mists and jagged cliffs, lies Lost and Found Island. X marks the spot where the treasure be buried, but remember, matey, the island holds many secrets and dangers. Stay sharp and trust yer instincts!\\n\\nFair winds and following seas to ye, brave pirate! Arrr!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 197, 'prompt_tokens': 51, 'total_tokens': 248, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_67802d9a6d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-b3f7109a-a9f8-47da-bb8e-32c076149e79-0' usage_metadata={'input_tokens': 51, 'output_tokens': 197, 'total_tokens': 248, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(template.format(island = \"Lost and Found\"))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the LLM\n",
    "as instructed in the course, let us try to configure the LLM. This includes things like setting the temperature. Temperature affects the randomness or creativity of the response. it is typically a value between 0.0 and 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://python.langchain.com/docs/integrations/chat/azure_chat_openai/\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/switching-endpoints\n",
    "llm_temp = AzureChatOpenAI(\n",
    "    api_version='2024-08-01-preview',# make sure this api_version matches what is the endpoint url below\n",
    "    azure_endpoint=\"https://intel-graph-openai.openai.azure.com/openai/deployments/igrt-gpt-4o-2024-10-22/chat/completions?api-version=2024-08-01-preview\",\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    verbose = True,\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Arrr, ye be seekin' the Lost and Found Island, eh? Aye, that be a tricky one to find, but ol' Cap'n here will guide ye true. Hoist the Jolly Roger and set yer course to the east, past the treacherous Siren's Cove. Keep a weather eye out for the twin peaks of Skull Mountain, for they be yer landmark.\\n\\nOnce ye spot the peaks, steer yer ship south by southwest until ye reach the Whispering Reefs. Navigate carefully, lest ye wreck upon the hidden rocks. From there, sail straight west until the waters grow calm and the air thick with mystery. \\n\\nYe should see the island shrouded in mist, with the ancient lighthouse standing tall. That be Lost and Found Island, where many a treasure hunter has sought their fortune. Good luck, matey, and may the winds be ever in yer favor! Arrr!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 186, 'prompt_tokens': 51, 'total_tokens': 237, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_67802d9a6d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-938f8b2b-7e97-4c7a-86cf-b738d52d3c72-0' usage_metadata={'input_tokens': 51, 'output_tokens': 186, 'total_tokens': 237, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "response = llm_temp.invoke(template.format(island = \"Lost and Found\"))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
