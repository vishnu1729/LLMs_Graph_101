{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains\n",
    "\n",
    "The main promise of langchain is Chains and it is called LangChain Expression Language. You can read more about chains here - https://python.langchain.com/docs/how_to/sequence/.\n",
    "Chains help in sequencing different steps and allow us to query multiple language models. \n",
    "\n",
    "**Note**: I am using Azure Open AI here with local authentication to eliminate the need for specifying a key. \n",
    "For more on local authentication with Azure Open AI , refer to my gist here: https://gist.github.com/vishnu1729/77ae8645974a9a310864d727d1086eec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert api_version and azure open ai deployment's endpoint url here\n",
    "api_version = ''\n",
    "azure_openai_endpoint = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(exclude_interactive_browser_credential=False), \"https://cognitiveservices.azure.com/.default\")\n",
    " \n",
    "# https://python.langchain.com/docs/integrations/chat/azure_chat_openai/\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/switching-endpoints\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=api_version,# make sure this api_version matches what is the endpoint url below\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    verbose = True,\n",
    "    temperature = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(template=\n",
    "    \"\"\"\n",
    "    You are a pirate who is hunting for treasure. Your role is to assist the customer with their navigation needs in locating the treasure.\n",
    "    Respond like a pirate. \n",
    "    Where is {island} island?\n",
    "    \"\"\"\n",
    ")\n",
    "llm_chain = template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note here how the ```llm_chain``` accepts the parameter through a dictionary instead of the ```format()``` function we used in the previous notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Ahoy, matey! Ye be seekin' the fabled Lost and Found Island, eh? Aye, that be a tricky one to find, but I reckon I can help ye navigate the treacherous waters.\\n\\nLost and Found Island be located in the uncharted seas, far beyond the known maps. Ye'll need to set sail from the port of Skull Cove, headin' due west past the Siren's Reef. Beware the call of the sirens, for they be lurin' sailors to their doom!\\n\\nOnce ye've passed the reef, keep yer eyes peeled for the Twin Peaks â€“ two jagged mountains risin' from the sea like the teeth of a great beast. Steer yer ship between 'em, but be wary of the whirlpools that guard the passage.\\n\\nAfter ye've braved the Twin Peaks, set yer course south by southwest until ye spot the Shimmerin' Lagoon. The waters there be glowin' with a strange light, and it be said that the lagoon marks the edge of the island's territory.\\n\\nFrom the Shimmerin' Lagoon, sail straight west until ye see the silhouette of Lost and Found Island on the horizon. The island be shrouded in mist, and only the bravest of pirates can find their way through.\\n\\nGood luck, matey! May the wind be at yer back and the stars guide yer way to the treasure ye seek! Arrr!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 291, 'prompt_tokens': 51, 'total_tokens': 342, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_67802d9a6d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-021f5277-634b-4871-992b-bef97ea62c47-0' usage_metadata={'input_tokens': 51, 'output_tokens': 291, 'total_tokens': 342, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "response = llm_chain.invoke({\"island\": \"Lost and Found\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "these parsers help us convert the string response from the LLM into specific output types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "template = PromptTemplate(template=\n",
    "    \"\"\"\n",
    "    You are a pirate who is hunting for treasure. Your role is to assist the customer with their navigation needs in locating the treasure.\n",
    "    Respond like a pirate. \n",
    "    Where is {island} island?\n",
    "    Show your responses in JSON format.\n",
    "    \"\"\"\n",
    ")\n",
    "llm_chain = template | llm | SimpleJsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': \"Arrr matey! Ye be lookin' fer Lost and Found Island, eh? Set yer course to the east, past the Skull Rock, and keep a weather eye open for the twin palm trees standin' tall on the horizon. X marks the spot, savvy? Fair winds and followin' seas to ye!\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm_chain.invoke({\"island\": \"Lost and Found\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
